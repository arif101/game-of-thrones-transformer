{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "92baf42e-c18f-478f-bd06-d0c4f8b4ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "import re\n",
    "import torch.nn as nn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "972a8a4b-c05f-4dd0-a402-90ac1d829625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    print(\"Using mps\")\n",
    "    torch.set_default_device(\"mps\") #will run metal performance shaders on Mac for better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "a12e6c2a-c848-4565-b3ef-382d6059fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('game_of_thrones.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "ebfee435-d024-422e-b507-e3e3002d6a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Song of Ice and Fire\n",
      "\n",
      "A Game of Thrones\n",
      "\n",
      "PROLOGUE\n",
      "\n",
      "We should start back, Gared urged as the woods began to grow dark around them.  The wildlings are dead.\n",
      "\n",
      "Do the dead frighten you? Ser Waymar Royce asked with just the hint of a smile.\n",
      "\n",
      "Gared did not rise to the bait. He was an old man, past fifty, and he had seen the lordlings come and go.  Dead is dead, he said.  We have no business with the dead.\n",
      "\n",
      "Are they dead? Royce asked softly.  What proof have we?\n",
      "\n",
      "Will saw them, Gared said.  If he says they are dead, that's proof enough for me.\n",
      "\n",
      "Will had known they would drag him into the quarrel sooner or later. He wished it had been later rather than sooner.  My mother told me that dead men sing no songs, he put in.\n",
      "\n",
      "My wet nurse said the same thing, Will, Royce replied.  Never believe anything you hear at a woman's tit. There are things to be learned even from the dead. His voice echoed, too loud in the twilit forest.\n",
      "\n",
      "We have a long ride before us, Gared pointed out.  Eight days, maybe n\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "1f7e85be-3e03-443a-9502-b6400db130ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = text.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "47860103-7b55-4035-bc74-0b0cdba70664",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_chars = ',?;.:/*!+-()[]{}\"\\'&'\n",
    "sentences = [re.sub(f'[{re.escape(special_chars)}]', ' \\g<0> ', s).split(' ') for s in lines] #tokenize sentences into words\n",
    "sentences = [[w for w in s if len(w)] for s in sentences] #remove null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "f0b852db-8b02-4ba0-8d8e-b2efbe57518b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A', 'Song', 'of', 'Ice', 'and', 'Fire'],\n",
       " [],\n",
       " ['A', 'Game', 'of', 'Thrones'],\n",
       " [],\n",
       " ['PROLOGUE'],\n",
       " [],\n",
       " ['We',\n",
       "  'should',\n",
       "  'start',\n",
       "  'back',\n",
       "  ',',\n",
       "  'Gared',\n",
       "  'urged',\n",
       "  'as',\n",
       "  'the',\n",
       "  'woods',\n",
       "  'began',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'dark',\n",
       "  'around',\n",
       "  'them',\n",
       "  '.',\n",
       "  'The',\n",
       "  'wildlings',\n",
       "  'are',\n",
       "  'dead',\n",
       "  '.'],\n",
       " []]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "52ec2a50-03de-4fec-adab-f1329c3fc04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for s in sentences:\n",
    "    for word in s:\n",
    "        vocab.add(word)\n",
    "vocab.add('<unk>')\n",
    "vocab.add('<s>')\n",
    "vocab.add('<pad>')\n",
    "vocab.add('\\n')\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "c22dd4dd-a0d2-43d0-a54e-53e79311e954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13395"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "d71fa71e-685c-4882-98fb-4ac04cc919d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = {word:i for i,word in enumerate(vocab)}\n",
    "reverse_lookup = {value:key for key,value in lookup.items()}\n",
    "encode = lambda x: [lookup[word] for word in x]    \n",
    "decode = lambda x: ' '.join([reverse_lookup[c] for c in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "2247933a-ebd5-4b8b-9460-ff6568d5d55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10877]"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "5c4c1250-bf77-49d3-b8c2-4d82db0a7cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for sentence in sentences:\n",
    "    if len(sentence) == 0:\n",
    "        data.append('\\n')\n",
    "        continue\n",
    "    for word in sentence:\n",
    "        data.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "9f6d6474-ba4c-4c81-884a-354942c18e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(data), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "ac67f9fa-e0c1-43a1-a52d-9aa0a84c6b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([360857]) torch.int64\n",
      "tensor([10218,  7756,  4517,  1902,  5017, 10379, 10877, 10218,  4141,  4517],\n",
      "       device='mps:0')\n",
      "A Song of Ice and Fire \n",
      " A Game of Thrones \n",
      " PROLOGUE \n",
      " We should start back , Gared urged as the woods began to grow dark around them . The wildlings are dead . \n",
      " Do the dead frighten you ? Ser Waymar Royce asked with just the hint of a smile . \n",
      " Gared did not rise to the bait . He was an old man , past fifty , and he had seen the lordlings come and go . Dead is dead , he said . We have no business with the dead . \n",
      " Are\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, data.dtype)\n",
    "\n",
    "print(data[:10])\n",
    "print(decode(data[:100].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "21507f39-86f4-4ae8-afd6-9afd86f96f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training = int(0.8*len(data))\n",
    "n_dev = int(0.9*len(data))\n",
    "train_data = data[:n_training]\n",
    "val_data = data[n_training:n_dev]\n",
    "test_data = data[n_dev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "466a2261-b03a-4964-b235-8344fe961f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is A, target is Song\n",
      "when input is A Song, target is of\n",
      "when input is A Song of, target is Ice\n",
      "when input is A Song of Ice, target is and\n",
      "when input is A Song of Ice and, target is Fire\n",
      "when input is A Song of Ice and Fire, target is \n",
      "\n",
      "when input is A Song of Ice and Fire \n",
      ", target is A\n",
      "when input is A Song of Ice and Fire \n",
      " A, target is Game\n",
      "when input is A Song of Ice and Fire \n",
      " A Game, target is of\n",
      "when input is A Song of Ice and Fire \n",
      " A Game of, target is Thrones\n"
     ]
    }
   ],
   "source": [
    "seq_len = 10\n",
    "x = train_data[:seq_len]\n",
    "y = train_data[1:seq_len+1]\n",
    "for t in range(seq_len):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    context = decode(context.tolist())\n",
    "    target = decode([target.item()])\n",
    "    \n",
    "    print(f\"when input is {context}, target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0debd4f-bbcc-48ef-a2c8-450f4df5b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "seq_len = 10\n",
    "def get_batch(batch_size, seq_len, split='train'):\n",
    "    datasets = {'train': train_data, 'val': val_data, 'test': test_data}\n",
    "    dataset = datasets[split]\n",
    "    ix = torch.randint(len(dataset) - seq_len, (batch_size,))\n",
    "    x = torch.stack([dataset[i:i+seq_len] for i in ix])\n",
    "    y = torch.stack([dataset[i+1:i+seq_len+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "3feb0cb4-38f2-4b12-9318-7c78c248e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = get_batch(batch_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "d827c481-ca8b-4519-8c2f-f8b63f837a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10]) torch.Size([4, 10])\n",
      "tensor([[13191,  4973,  8219,  3768,  4364, 11823,  3183, 12923,  8452,  5086],\n",
      "        [ 4676,  4500,  5017, 11569, 11746,  5329,  4973, 13346,  9686,  8452],\n",
      "        [ 7733,  8121,  7384,  2689,  6100,  4349,  5677, 13284,  9375, 13154],\n",
      "        [ 4973, 10877, 11741, 10053,  3768,  4364, 11174,  8446,  9803,  6100]],\n",
      "       device='mps:0')\n",
      "tensor([[ 4973,  8219,  3768,  4364, 11823,  3183, 12923,  8452,  5086, 12923],\n",
      "        [ 4500,  5017, 11569, 11746,  5329,  4973, 13346,  9686,  8452,  9356],\n",
      "        [ 8121,  7384,  2689,  6100,  4349,  5677, 13284,  9375, 13154,  8452],\n",
      "        [10877, 11741, 10053,  3768,  4364, 11174,  8446,  9803,  6100, 11383]],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(xb.shape, yb.shape)\n",
    "print(xb) #input to transformer\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "919bfd04-f278-43ea-a72a-91e8a614d13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is: me, target is: .\n",
      "when input is: me ., target is: What\n",
      "when input is: me . What, target is: '\n",
      "when input is: me . What ', target is: s\n",
      "when input is: me . What ' s, target is: wrong\n",
      "when input is: me . What ' s wrong, target is: with\n",
      "when input is: me . What ' s wrong with, target is: you\n",
      "when input is: me . What ' s wrong with you, target is: ,\n",
      "when input is: me . What ' s wrong with you ,, target is: are\n",
      "when input is: me . What ' s wrong with you , are, target is: you\n"
     ]
    }
   ],
   "source": [
    "for b in range(1):\n",
    "    for t in range(seq_len):\n",
    "        context = xb[b][:t+1]\n",
    "        target = yb[b][t]\n",
    "        context = decode(context.tolist())\n",
    "        target = decode([target.item()])\n",
    "        print(f\"when input is: {context}, target is: {target}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "9d44cc67-b9b7-4523-809d-d31373d10731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10, 24])\n",
      "torch.Size([10, 24])\n",
      "torch.Size([10, 24])\n"
     ]
    }
   ],
   "source": [
    "emb = nn.Embedding(vocab_size, 24)\n",
    "print(emb(xb).shape) # (B, T, C)\n",
    "\n",
    "pe = torch.zeros(seq_len, 24)\n",
    "print(pe[:seq_len, :24].shape)\n",
    "print(pe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "06236d32-3249-4b59-8f78-7252810aff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, embd_dim, seq_len):\n",
    "        super().__init__()\n",
    "        self.pe = torch.zeros(seq_len, embd_dim) # (T, C)\n",
    "        self.pe.requires_grad = False\n",
    "\n",
    "        pos = torch.arange(0, seq_len).float()\n",
    "        pos = pos.unsqueeze(dim=1)\n",
    "\n",
    "        even_positions = torch.arange(0, embd_dim, 2).float()\n",
    "        self.pe[:, 0::2] = torch.sin(pos / (10000 ** (even_positions / embd_dim)))\n",
    "        self.pe[:, 1::2] = torch.cos(pos / (10000 ** (even_positions / embd_dim)))\n",
    "        # compute sinusoidal positional embeddings as in the attention paper\n",
    "        \n",
    "        \n",
    "    def forward(self, x): # x is of shape (B, T, C)\n",
    "        B, T = x.shape\n",
    "        return self.pe[:T, :] # (T, C)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "938c4951-3716-45d1-8830-75c685ec1622",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module): #single head of self attention\n",
    "    def __init__(self, n_head, embd_dim, seq_len, dropout):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(embd_dim, n_head, bias=False)\n",
    "        self.key = nn.Linear(embd_dim, n_head, bias=False)\n",
    "        self.value = nn.Linear(embd_dim, n_head, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(seq_len, seq_len)))\n",
    "        self.n_head = n_head\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape # batch, time (seq_len), channel (# of features, or # of embedding dimensions)\n",
    "        key = self.key(x) # (B, T, n_head)\n",
    "        query = self.query(x) # (B, T, n_head)\n",
    "\n",
    "        # compute attention scores\n",
    "        wei = query @ key.transpose(-2, -1) * self.n_head ** -0.5  # (B, T, n_head) x (B, n_head, T) = (B, T, T)\n",
    "        # internally, pyTorch is doing:\n",
    "        # for every b in B (batch_dim) do: matrix multiply of (T, C) x (C, T) = (T, T) for every b = (B, T, T)\n",
    "        #initialize with std dev of 0 and variance of 1 so that softmax works properly ( does not converge to one hot encodings)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        value = self.value(x) # (B, T, n_head)\n",
    "        out = wei @ value # (B, T, T) x (B, T, n_head) = (B, T, n_head)\n",
    "        return out      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "00c6992d-d503-4c0e-988f-0b224065ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embd_dim = 32\n",
    "n_head = 5\n",
    "emb = nn.Embedding(vocab_size, embd_dim)\n",
    "pe = PositionalEncoding(embd_dim, seq_len)\n",
    "h = Head(n_head, embd_dim, seq_len, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "5467ed3d-9c9b-42bf-81c8-bc4ae0e709bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 5])"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = emb(xb) + pe(xb)\n",
    "x = h(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "4c6d0ef3-f639-4947-a5ad-7619bd6c3f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, n_heads, head_size, embd_dim, seq_len, dropout):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size, embd_dim, seq_len, dropout) for _ in range(n_heads)])\n",
    "        self.proj = nn.Linear(embd_dim, embd_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "f4e3dd96-33d6-4092-a001-f9d0b509f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, embd_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embd_dim, 4 * embd_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embd_dim, embd_dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "3d5ccfbd-2d6e-42b5-b2f6-e2d8dca453a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, embd_dim, n_heads, seq_len, dropout):\n",
    "        super().__init__()\n",
    "        head_size = embd_dim // n_heads\n",
    "        self.sa = MultiHeadAttention(n_heads, head_size, embd_dim, seq_len, dropout)\n",
    "        self.ffwd = FeedForward(embd_dim, dropout)\n",
    "        self.ln1 = nn.LayerNorm(embd_dim)\n",
    "        self.ln2 = nn.LayerNorm(embd_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x)) #skip connection\n",
    "        x = x + self.ffwd(self.ln2(x)) #skip connection\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "7a20cf86-1e7a-4ae0-896a-37e11bff015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embd_dim, seq_len, n_heads, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, embd_dim)\n",
    "        self.pe = PositionalEncoding(embd_dim, seq_len)\n",
    "        self.blocks = nn.Sequential(*[Block(embd_dim, n_heads, seq_len, dropout) for _ in range(n_layers)])\n",
    "        self.ln = nn.LayerNorm(embd_dim)\n",
    "        self.lm_head = nn.Linear(embd_dim, vocab_size)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        B, T = x.shape\n",
    "        x = self.emb(x) + self.pe(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            \n",
    "        return logits, loss   \n",
    "\n",
    "    def generate(self, context, max_new_tokens):\n",
    "        # context is (B, T) shape \n",
    "        for _ in range(max_new_tokens):\n",
    "            context_max = context[:, -self.seq_len:] #crop context to get last seq_len tokens\n",
    "            logits, loss = self(context_max) #get the predictions\n",
    "            logits = logits[:, -1, :] # new shape is (B, C)\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            next_token = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            context = torch.cat((context, next_token), dim=1) # (B, T+1)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "f31baf58-66ca-465d-94ff-ed1750c900df",
   "metadata": {},
   "outputs": [],
   "source": [
    "embd_dim = 16\n",
    "batch_size = 8\n",
    "n_heads = 4\n",
    "n_layers = 4\n",
    "dropout = 0.1\n",
    "seq_len = 8\n",
    "\n",
    "model = LanguageModel(vocab_size, embd_dim, seq_len, n_heads, n_layers, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "b0480726-9e10-40f5-bc85-5c0b1c9425ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.454995 M parameters\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "60952b72-4e4e-4931-80c9-cc951afc2408",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "856bc189-52e9-4db6-8b32-b6f4fee58f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_loss(eval_iters):\n",
    "    with torch.no_grad():\n",
    "        out = {}\n",
    "        model.eval()\n",
    "        for split in ['train', 'val']:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for k in range(eval_iters):\n",
    "                X, Y = get_batch(batch_size, seq_len, split)\n",
    "                logits, loss = model(X, Y)\n",
    "                losses[k] = loss.item()\n",
    "            out[split] = losses.mean()\n",
    "        model.train()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "ef61c4da-3670-4612-bf69-c1db8124baea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.9999, val loss 5.6076\n",
      "step 100: train loss 4.9774, val loss 5.5121\n",
      "step 200: train loss 4.8922, val loss 5.4117\n",
      "step 300: train loss 4.9755, val loss 5.4341\n",
      "step 400: train loss 4.9473, val loss 5.4772\n",
      "step 500: train loss 4.9234, val loss 5.5013\n",
      "step 600: train loss 4.9295, val loss 5.4918\n",
      "step 700: train loss 5.0022, val loss 5.3713\n",
      "step 800: train loss 4.9329, val loss 5.4762\n",
      "step 900: train loss 4.9393, val loss 5.4992\n",
      "step 999: train loss 4.9339, val loss 5.5361\n"
     ]
    }
   ],
   "source": [
    "eval_interval = 100\n",
    "eval_iters = 100\n",
    "max_iters = 1000\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss(eval_iters)\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    xb, yb = get_batch(batch_size, seq_len)\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "e7eff115-6e86-41ce-b5c6-f752cb340eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13095, 3768]"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"He '\".split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "c3dcadc9-1e8b-476b-a03d-7184158eddbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He ' s ride himself every year . Khal Drogo century sister ' s death was up at first particular friends , Marillion . \n",
      " Give water , thin legs must make them you here out , part home , now . His men doors time you think he said Mormont gave him , the center of the east one and Catelyn ' s floor and shelters . You had told Bronn said Baelish truly see her . shuddered , so skulls around the stone parapets and at him , Queen \n",
      " For a helm with them when I was because Jon\n"
     ]
    }
   ],
   "source": [
    "# encode('\\n') = 10877\n",
    "context = torch.tensor([13095, 3768], dtype=torch.long).view(1, 2)\n",
    "# context = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(model.generate(context, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e67aa60-22a0-46cb-a993-07f84e060aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
